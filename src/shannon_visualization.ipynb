{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algoritmo\n",
    "\n",
    "- 1- Inicia-se com duas palavras aleatórias;\n",
    "- 2- Escolhe-se a próxima palavra de forma aleatória levando em consideração a distribuição de probabilidade;\n",
    "- 3- Continua o passo anterior até um critério de parada (word_count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShannonVisualizationMethod:\n",
    "    def __init__(self, corpus_txt_path_list):\n",
    "        self.tokens = self._aggregate_corpus(corpus_txt_path_list)\n",
    "    \n",
    "    def _generate_tokens(self, corpus_txt_path):\n",
    "        regex = \"[a-zA-ZçÇãÃõÕáÁéÉíÍóÓúÚâÂêÊîÎôÔûÛàÀ]+\"\n",
    "        corpus = open(corpus_txt_path, encoding='UTF-8').read()\n",
    "        tokens = re.findall(regex, corpus)\n",
    "        return tokens\n",
    "    \n",
    "    def _aggregate_corpus(self, corpus_txt_path_list):\n",
    "        tokens = []\n",
    "        for corpus_txt_path in corpus_txt_path_list:\n",
    "            tokens += self._generate_tokens(corpus_txt_path)\n",
    "        return tokens\n",
    "    \n",
    "    def _choose_next_word(self, start_sentence_list):\n",
    "        n = len(start_sentence_list) + 1\n",
    "        \n",
    "        # Denominator cal \n",
    "        count_denom = Counter(zip(*(self.tokens[i:] for i in range(n - 1))))[tuple(start_sentence_list)]\n",
    "\n",
    "        if count_denom == 0:\n",
    "            raise Exception(\"The start sentence list does not exist in the corpus\")\n",
    "\n",
    "        n_grams = Counter(zip(*(self.tokens[i:] for i in range(n))))\n",
    "\n",
    "        count_n_grams = [n_grams[tuple(start_sentence_list + [token])] for token in self.tokens]\n",
    "\n",
    "        n_gram_probabilities = np.array(count_n_grams) / count_denom\n",
    "\n",
    "        # Remove zero probabilities\n",
    "        set_words = [(n_gram_probabilities[i], self.tokens[i]) for i in range(len(n_gram_probabilities)) if\n",
    "                        n_gram_probabilities[i] > 0]\n",
    "\n",
    "        # Make a set of words\n",
    "        set_words = set(set_words)\n",
    "\n",
    "        # Choose next word\n",
    "        prob_words = [st[0] for st in set_words]\n",
    "        candidate_words = [st[1] for st in set_words]\n",
    "\n",
    "        next_word = np.random.choice(candidate_words, 1, p=prob_words).item()\n",
    "\n",
    "        return next_word\n",
    "\n",
    "    def generate_text(self, start_sentence_list, words_count=10):\n",
    "        generated_text_str = ' '.join(start_sentence_list)\n",
    "        \n",
    "        for _ in range(words_count):\n",
    "            generated_word = self._choose_next_word(start_sentence_list)\n",
    "            start_sentence_list.pop(0)  # removes first word\n",
    "            start_sentence_list.append(generated_word)\n",
    "\n",
    "            generated_text_str = generated_text_str + \" \" + generated_word\n",
    "\n",
    "        return generated_text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../movie_scripts'\n",
    "corpus_txt_path_list = [os.path.join('../movie_scripts', file_path) for file_path in os.listdir(dataset_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "shannon_visu = ShannonVisualizationMethod(corpus_txt_path_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am not a dog EMIL For five years I paid for the movie When he took me home he said we should go on a Goddamn trim hunt stop moaning HAMMOND Speakin of moans my Stomach is startin to growl CATES We eat when I say that Cameron s love is pure Purer than say Joey Dorsey s PATRICK Dorsey can plow whoever he wants I m just a single dad out here blowing like dust in the wind Ed shakes Julie s hand and gives hima soda TONY is puzzled DISSOLVE Tony is siting in a chair with violin in hand'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shannon_visu.generate_text(\n",
    "    [\"I\", \"am\", \"not\"],\n",
    "    words_count=100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
